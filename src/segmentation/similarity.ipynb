{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from ast import literal_eval\n",
    "\n",
    "# load data\n",
    "datafile_path = \"../../data/raw\"\n",
    "\n",
    "data = os.listdir(datafile_path)\n",
    "data = [datafile_path + \"/\" + path for path in data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input = text, model=model).data[0].embedding\n",
    "\n",
    "# matrix = np.vstack(df.embedding.values)\n",
    "# matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from ocr.mistral import mistral_ocr\n",
    "from mistralai import Mistral\n",
    "\n",
    "\n",
    "path = \"/Users/amarkanaka/repos/pageStreamSegmentation/2024.02.14 RELEASE 24-013 RELEASE_2nd Interim Production_pages 401-500.pdf\"\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "client = Mistral(api_key=MISTRAL_API_KEY)\n",
    "pages = mistral_ocr(path, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4-turbo\")\n",
    "def num_tokens_by_tiktoken(text: str) -> int:\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "for idx in range(len(pages)):\n",
    "  num_tokens = num_tokens_by_tiktoken(pages[idx])\n",
    "  num_tokens_left = num_tokens\n",
    "  curr_num = 0\n",
    "  insert_idx = idx\n",
    "  text = pages[idx]\n",
    "  while(num_tokens_left > 8192):\n",
    "    curr_text = text[curr_num:curr_num + 8000]\n",
    "    pages.insert(insert_idx, curr_text)\n",
    "    curr_num += 8000\n",
    "    num_tokens_left -= 8000\n",
    "    insert_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1868\n"
     ]
    }
   ],
   "source": [
    "max_tokens = 0\n",
    "for page in pages:\n",
    "    num_tokens = num_tokens_by_tiktoken(page)\n",
    "    if num_tokens > max_tokens:\n",
    "        max_tokens = num_tokens\n",
    "print(max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [get_embedding(page) for page in pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Wrote 47 split PDFs to /Users/amarkanaka/repos/pageStreamSegmentation/data/itemized/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ic_similarity = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75]\n",
    "# for sim in ic_similarity:\n",
    "\n",
    "# Compute pairwise similarities\n",
    "similarities = [np.dot(embeddings[i], embeddings[i+1]) for i in range(len(embeddings)-1)]\n",
    "# Mark segment boundaries where similarity drops below threshold\n",
    "threshold = 0.51  # This is just an example value; tune for your data\n",
    "boundaries = [1 if sim < threshold else 0 for sim in similarities]\n",
    "\n",
    "if boundaries[-1] == 0:\n",
    "  boundaries.append(0)\n",
    "else:\n",
    "  boundaries.append(1)\n",
    "\n",
    "\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "# Path to your 100-page PDF\n",
    "input_pdf_path = path\n",
    "\n",
    "# Your split list (copy your list here)\n",
    "split_flags = boundaries\n",
    "\n",
    "# Check length matches the PDF\n",
    "reader = PdfReader(input_pdf_path)\n",
    "num_pages = len(reader.pages)\n",
    "assert len(split_flags) == num_pages, \"Length of split_flags must equal number of PDF pages!\"\n",
    "\n",
    "out_dir = \"/Users/amarkanaka/repos/pageStreamSegmentation/data/itemized\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "start = 0\n",
    "doc_num = 1\n",
    "\n",
    "for i, flag in enumerate(split_flags):\n",
    "    # If flag is 1, end the current document at this page\n",
    "    if flag == 1:\n",
    "        writer = PdfWriter()\n",
    "        for j in range(start, i+1):  # Include the current page\n",
    "            writer.add_page(reader.pages[j])\n",
    "        output_path = os.path.join(out_dir, f\"split_{doc_num:03d}.pdf\")\n",
    "        with open(output_path, \"wb\") as out_f:\n",
    "            writer.write(out_f)\n",
    "        doc_num += 1\n",
    "        start = i + 1  # Start the next doc at the next page\n",
    "\n",
    "# Optionally, if last split is not at end, you could add a check, but your list should cover all pages\n",
    "print(f\"Done! Wrote {doc_num-1} split PDFs to {out_dir}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tune Inter-Cluster Similarity Threshold on Validation Set and Benchmark Results on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read val.txt line by line, creating clusters of ~200 pages, and do hyperparameter tuning\n",
    "ic_similarity = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75]\n",
    "val_folders = set()\n",
    "current_doc = \"\"\n",
    "append_path = \"/Users/amarkanaka/repos/pageStreamSegmentation/\"\n",
    "with open(append_path + \"data/val.txt\") as f:\n",
    "    page_count = 0\n",
    "    val_folder = set()\n",
    "    is_within_doc = False\n",
    "    curr_doc = \"\"\n",
    "    for line in f:\n",
    "        next_doc = line.split()[1]\n",
    "        if next_doc == \"name\":\n",
    "            continue\n",
    "        else:\n",
    "            if curr_doc == next_doc:\n",
    "                is_within_doc = True\n",
    "            else:\n",
    "                is_within_doc = False\n",
    "            curr_doc = next_doc\n",
    "            if page_count < 150 or is_within_doc:\n",
    "                val_folder.add(curr_doc)\n",
    "                page_count += 1\n",
    "            else:\n",
    "                val_folders.add(frozenset(val_folder))\n",
    "                val_folder.clear()\n",
    "                page_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'data/raw/ghwb_0786.pdf',\n",
       "            'data/raw/neal_0278.pdf',\n",
       "            'data/raw/neal_0712.pdf',\n",
       "            'data/raw/pcast0002.pdf',\n",
       "            'data/raw/pcast0007.pdf',\n",
       "            'data/raw/pcast0052.pdf'}),\n",
       " frozenset({'data/raw/ghwb_0196.pdf',\n",
       "            'data/raw/ghwb_0522.pdf',\n",
       "            'data/raw/ghwb_0564.pdf',\n",
       "            'data/raw/ghwb_0608.pdf',\n",
       "            'data/raw/ghwb_0611.pdf',\n",
       "            'data/raw/ghwb_0732.pdf',\n",
       "            'data/raw/ghwb_0937.pdf',\n",
       "            'data/raw/ghwb_1157.pdf',\n",
       "            'data/raw/neal_0289.pdf',\n",
       "            'data/raw/neal_0312.pdf',\n",
       "            'data/raw/neal_0344.pdf',\n",
       "            'data/raw/pcast0003.pdf',\n",
       "            'data/raw/pcast0058.pdf'}),\n",
       " frozenset({'data/raw/ghwb_0165.pdf',\n",
       "            'data/raw/ghwb_0189.pdf',\n",
       "            'data/raw/ghwb_0248.pdf',\n",
       "            'data/raw/ghwb_0376.pdf',\n",
       "            'data/raw/ghwb_0383.pdf',\n",
       "            'data/raw/ghwb_0408.pdf',\n",
       "            'data/raw/ghwb_0425.pdf',\n",
       "            'data/raw/ghwb_0540.pdf',\n",
       "            'data/raw/ghwb_0561.pdf',\n",
       "            'data/raw/ghwb_0590.pdf',\n",
       "            'data/raw/ghwb_0591.pdf',\n",
       "            'data/raw/ghwb_0617.pdf',\n",
       "            'data/raw/ghwb_0628.pdf',\n",
       "            'data/raw/ghwb_0748.pdf',\n",
       "            'data/raw/ghwb_0774.pdf',\n",
       "            'data/raw/ghwb_0787.pdf',\n",
       "            'data/raw/ghwb_0838.pdf',\n",
       "            'data/raw/ghwb_0924.pdf',\n",
       "            'data/raw/ghwb_1005.pdf',\n",
       "            'data/raw/ghwb_1007.pdf',\n",
       "            'data/raw/ghwb_1177.pdf',\n",
       "            'data/raw/ghwb_1185.pdf',\n",
       "            'data/raw/gwb_0007.pdf',\n",
       "            'data/raw/neal_0100.pdf',\n",
       "            'data/raw/neal_0187.pdf',\n",
       "            'data/raw/neal_0261.pdf',\n",
       "            'data/raw/neal_0294.pdf',\n",
       "            'data/raw/neal_0297.pdf',\n",
       "            'data/raw/neal_0305.pdf',\n",
       "            'data/raw/neal_0476.pdf',\n",
       "            'data/raw/neal_0481.pdf',\n",
       "            'data/raw/neal_0718.pdf',\n",
       "            'data/raw/neal_0722.pdf',\n",
       "            'data/raw/pcast0017.pdf',\n",
       "            'data/raw/pcast0050.pdf'}),\n",
       " frozenset({'data/raw/ghwb_0339.pdf',\n",
       "            'data/raw/ghwb_0501.pdf',\n",
       "            'data/raw/ghwb_0515.pdf',\n",
       "            'data/raw/ghwb_0552.pdf',\n",
       "            'data/raw/ghwb_0702.pdf',\n",
       "            'data/raw/ghwb_0717.pdf',\n",
       "            'data/raw/ghwb_0737.pdf',\n",
       "            'data/raw/ghwb_0740.pdf',\n",
       "            'data/raw/ghwb_0833.pdf',\n",
       "            'data/raw/ghwb_1002.pdf',\n",
       "            'data/raw/ghwb_1009.pdf',\n",
       "            'data/raw/jhg_0005.pdf',\n",
       "            'data/raw/neal_0144.pdf',\n",
       "            'data/raw/neal_0282.pdf',\n",
       "            'data/raw/neal_0324.pdf',\n",
       "            'data/raw/neal_0326.pdf',\n",
       "            'data/raw/neal_0332.pdf',\n",
       "            'data/raw/pcast0075.pdf',\n",
       "            'data/raw/schaal_full_transcript.pdf'}),\n",
       " frozenset({'data/raw/ghwb_0197.pdf',\n",
       "            'data/raw/ghwb_0247.pdf',\n",
       "            'data/raw/ghwb_0367.pdf',\n",
       "            'data/raw/ghwb_0431.pdf',\n",
       "            'data/raw/ghwb_0534.pdf',\n",
       "            'data/raw/ghwb_0541.pdf',\n",
       "            'data/raw/ghwb_0582.pdf',\n",
       "            'data/raw/ghwb_0594.pdf',\n",
       "            'data/raw/ghwb_0744.pdf',\n",
       "            'data/raw/ghwb_0752.pdf',\n",
       "            'data/raw/ghwb_0828.pdf',\n",
       "            'data/raw/ghwb_0830.pdf',\n",
       "            'data/raw/ghwb_0836.pdf',\n",
       "            'data/raw/ghwb_0926.pdf',\n",
       "            'data/raw/ghwb_1031.pdf',\n",
       "            'data/raw/ghwb_1036.pdf',\n",
       "            'data/raw/jhg_0010.pdf',\n",
       "            'data/raw/neal_0081.pdf',\n",
       "            'data/raw/neal_0095.pdf',\n",
       "            'data/raw/neal_0263.pdf',\n",
       "            'data/raw/neal_0275.pdf',\n",
       "            'data/raw/neal_0599.pdf',\n",
       "            'data/raw/neal_0728.pdf',\n",
       "            'data/raw/neal_0739.pdf',\n",
       "            'data/raw/neal_0743.pdf',\n",
       "            'data/raw/pcast0010.pdf'})}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_1.8.0_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
